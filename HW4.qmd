---
title: "Biostat 203B Homework 4"
subtitle: Due Mar 24 @ 11:59PM
author: Cordelia Lee UID:105361901
format:
  html:
    theme: cosmo
    embed-resources: true
    number-sections: true
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
knitr:
  opts_chunk: 
    cache: false    
    echo: true
    fig.align: 'center'
    fig.width: 6
    fig.height: 4
    message: FALSE
---

Display machine information:
```{r}
#| eval: true

sessionInfo()
```
Load database libraries and the tidyverse frontend:
```{r}
#| eval: true

suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(glmnet))
```

## Predicting 30-day mortality

Using the ICU cohort `icu_cohort.rds` you built in Homework 3, develop at least three analytic approaches for predicting the 30-day mortality of patients admitted to ICU using demographic information (gender, age, marital status, ethnicity), first lab measurements during ICU stay, and first vital measurements during ICU stay. For example, you can use (1) logistic regression with elastic net (lasso + ridge) penalty (e.g., glmnet or keras package), (2) random forest, (3) boosting, and (4) support vector machines, or (5) MLP neural network (keras package)

1. Partition data into 50% training set and 50% test set. Stratify partitioning according the 30-day mortality status.
```{r}
library(GGally)
library(gtsummary)
library(ranger)
library(tidyverse)
library(tidymodels)
library(GGally)
library(xgboost)
# load the data "icu_cohort"
icu_cohort <- read_rds("mimiciv_shiny/icu_cohort.rds")%>% 
# only keep the variables wanted. discarded those with a lot NAs
select ("gender", "marital_status", "ethnicity",
        "thirty_day_mort", "item_50912", "item_50971", "item_50912",
        "item_50971", "item_50983", "item_50902", "item_50882", "item_51221",
        "item_51301", "item_50931", "item_220045", "item_220181", 
        "item_220179", "item_223761", "item_220210")

set.seed(203)

#splitting data 
data_split <- initial_split(
  icu_cohort, 
  # stratify by thirty day mortality
  strata = "thirty_day_mort", 
  prop = 0.5
  )
data_split

icu_cohort_other <- training(data_split)
dim(icu_cohort_other)

icu_cohort_test <- testing(data_split)
dim(icu_cohort_test)
```
## Logistic Regression 
2. Train and tune the models using the training set.
```{r}
logit_recipe <- 
  recipe(
    thirty_day_mort ~ ., 
    data = icu_cohort
  ) %>%
  # ignore missing data and impute because sample size is large
  # only impute the variables of interest
   step_impute_mode(marital_status, ethnicity, gender) %>%
   step_impute_mean(item_50912, item_50971, item_50912,
       item_50971,
       item_50983,
      item_50902,
      item_50882,
      item_51221,
      item_51301,
      item_50931,
     item_220045,
      item_220181,
      item_220179,
      item_223761,
      item_220210)%>%
  # create traditional dummy variables
  step_dummy(all_nominal_predictors()) %>%
  # zero-variance filter
  step_zv(all_numeric_predictors()) %>% 
  # center and scale numeric data
  step_normalize(all_numeric_predictors()) %>%
  # estimate the means and standard deviations
  prep(training = icu_cohort_other, retain = TRUE)
logit_recipe
```
Model 
```{r}
logit_mod <- 
  logistic_reg(
    penalty = tune(), 
    mixture = tune()
  ) %>% 
  set_engine("glmnet", standardize = FALSE)
logit_mod
```
Workflow
```{r}
logit_wf <- workflow() %>%
  add_recipe(logit_recipe) %>%
  add_model(logit_mod)
logit_wf
```
Tuning grid 
```{r}
param_grid <- grid_regular(
  penalty(range = c(-6, 3)), 
  mixture(),
  levels = c(100, 5)
  )
param_grid
```
Cross-validation
```{r}
set.seed(203)

folds <- vfold_cv(icu_cohort_other, v = 5)
folds
```
fit CV
```{r}
#str(icu_cohort)
logit_fit <- logit_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid,
    metrics = metric_set(roc_auc, accuracy)
    )
logit_fit

```


```{r}
logit_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = penalty, y = mean, color = mixture)) +
  geom_point() +
  labs(x = "Penalty", y = "CV AUC") +
  scale_x_log10()
```

```{r}
logit_fit %>%
  show_best("roc_auc")
```


```{r}
best_logit <- logit_fit %>%
  select_best("roc_auc")
best_logit
```

```{r}
best_logit <- logit_fit %>%
  select_best("roc_auc")
best_logit
```
```{r}
# Final workflow
final_wf <- logit_wf %>%
  finalize_workflow(best_logit)
final_wf
```
```{r}
# Fit the whole training set, then predict the test cases
final_fit <- 
  final_wf %>%
  last_fit(data_split)
final_fit
```
```{r}
# Test metrics
final_fit %>% 
  collect_metrics()
```


##Random Forest 
```{r}
rf_recipe <- 
  recipe(
    thirty_day_mort ~., 
    data = icu_cohort_other
  ) %>%
  # create traditional dummy variables (not necessary for random forest in R)
  # step_dummy(all_nominal()) %>%
 step_impute_mode(marital_status, ethnicity, gender) %>%
   step_impute_mean(item_50912, item_50971, item_50912,
    item_50971,
     item_50983,
      item_50902,
      item_50882,
      item_51221,
      item_51301,
      item_50931,
     item_220045,
      item_220181,
      item_220179,
      item_223761,
      item_220210) %>%
  # zero-variance filter
  step_zv(all_numeric_predictors()) %>% 
  # # center and scale numeric data (not necessary for random forest)
  # step_normalize(all_numeric_predictors()) %>%
  # estimate the means and standard deviations
  prep(training = icu_cohort_other, retain = TRUE)
rf_recipe
```
Model 
```{r}
rf_mod <- 
  rand_forest(
    mode = "classification",
    # Number of predictors randomly sampled in each split
    mtry = tune(),
    # Number of trees in ensemble
    trees = tune()
  ) %>% 
  set_engine("ranger")
rf_mod
```

```{r}
rf_wf <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_mod)
rf_wf
```
Tuning grid 
```{r}
param_grid <- grid_regular(
  trees(range = c(100L, 300L)), 
  mtry(range = c(1L, 5L)),
  levels = c(3, 5)
  )
param_grid
```
Cross validation
```{r}
rf_fit <- rf_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid,
    metrics = metric_set(roc_auc, accuracy)
    )
rf_fit
```

```{r}
rf_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = trees, y = mean, color = mtry)) +
  geom_point() + 
  # geom_line() + 
  labs(x = "Num. of Trees", y = "CV AUC")
```
```{r}
rf_fit %>%
  show_best("roc_auc")
```

```{r}
best_rf <- rf_fit %>%
  select_best("roc_auc")
best_rf
```

Finalizing Model
```{r}
# Final workflow
final_wf <- rf_wf %>%
  finalize_workflow(best_rf)
final_wf
```

```{r}
# Fit the whole training set, then predict the test cases
final_fit <- 
  final_wf %>%
  last_fit(data_split)
final_fit
```

```{r}
# Test metrics
final_fit %>% 
  collect_metrics()
```

##XGBoost
Data summary
```{r}
# Numerical summaries stratified by the outcome `AHD`.
icu_cohort %>% tbl_summary(by = thirty_day_mort)
```

```{r}
gb_recipe <- 
  recipe(
    thirty_day_mort ~ ., 
    data = icu_cohort_other
  ) %>%
 step_impute_mode(marital_status, ethnicity, gender) %>%
   step_impute_mean(item_50912, item_50971, item_50912,
       item_50971,
     item_50983,
      item_50902,
      item_50882,
      item_51221,
      item_51301,
      item_50931,
     item_220045,
      item_220181,
      item_220179,
      item_223761,
      item_220210) %>%
  step_dummy(all_nominal_predictors()) %>%
  # zero-variance filter
  step_zv(all_numeric_predictors()) %>% 
  # estimate the means and standard deviations
  prep(training = icu_cohort_other, retain = TRUE)
gb_recipe
  
```
Model 
```{r}
gb_mod <- 
  boost_tree(
    mode = "classification",
    trees = 1000, 
    tree_depth = tune(),
    learn_rate = tune()
  ) %>% 
  set_engine("xgboost")
gb_mod
```
Workflow and pipeline
```{r}
gb_wf <- workflow() %>%
  add_recipe(gb_recipe) %>%
  add_model(gb_mod)
gb_wf
```
Tuning grid 
```{r}
param_grid <- grid_regular(
  tree_depth(range = c(1L, 3L)),
  learn_rate(range = c(-5, 2), trans = log10_trans()),
  levels = c(3, 10)
  )
param_grid
```

```{r}
gb_fit <- gb_wf %>%
  tune_grid(
    resamples = folds,
    grid = param_grid,
    metrics = metric_set(roc_auc, accuracy)
    )
gb_fit
```
Visualize results 
```{r}
gb_fit %>%
  collect_metrics() %>%
  print(width = Inf) %>%
  filter(.metric == "roc_auc") %>%
  ggplot(mapping = aes(x = learn_rate, y = mean, color = tree_depth)) +
  geom_point() +
  labs(x = "Learning Rate", y = "CV AUC") +
  scale_x_log10()
```

```{r}
gb_fit %>%
  show_best("roc_auc")
```

select the best model 
```{r}
best_gb <- gb_fit %>%
  select_best("roc_auc")
best_gb
```

finalize our model
```{r}
# Final workflow
final_wf <- gb_wf %>%
  finalize_workflow(best_gb)
final_wf
```

```{r}
# Fit the whole training set, then predict the test cases
final_fit <- 
  final_wf %>%
  last_fit(data_split)
final_fit
```

```{r}
# Test metrics
final_fit %>% 
  collect_metrics()
```
From the three models selected, it appears that XGBoost has the highest ROC_AUC
and has a slightly higher accuracy than random forest. 



